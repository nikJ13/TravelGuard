{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "def prepare(filepath):\n",
    "    IMG_SIZE=150\n",
    "    img_array=cv2.imread(filepath,cv2.IMREAD_GRAYSCALE)\n",
    "    new_array=cv2.resize(img_array,(IMG_SIZE,IMG_SIZE))\n",
    "    return new_array.reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "\n",
    "model=tf.keras.models.load_model(\"64x3-CNN.model\")\n",
    "\n",
    "prediction=model.predict([prepare('img1.JPG')])\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/navneeth/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/navneeth/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/navneeth/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/navneeth/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/navneeth/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/navneeth/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/navneeth/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/navneeth/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/navneeth/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/navneeth/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/navneeth/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/navneeth/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/navneeth/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/navneeth/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/navneeth/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/navneeth/.local/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "done\n",
      "Found 1 faces\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "\n",
    "from resizeimage import resizeimage\n",
    "import simpleaudio as sa\n",
    "\n",
    "filename = 'alarm.wav'\n",
    "wave_obj = sa.WaveObject.from_wave_file(filename)\n",
    "\n",
    "CATEGORIES=[\"yes\",\"no\"]\n",
    "\n",
    "def prepare(filepath):\n",
    "    IMG_SIZE=150\n",
    "    img_array=cv2.imread(filepath,cv2.IMREAD_GRAYSCALE)\n",
    "    new_array=cv2.resize(img_array,(IMG_SIZE,IMG_SIZE))\n",
    "    return new_array.reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "\n",
    "model=tf.keras.models.load_model(\"64x3-CNN.model\")\n",
    "\n",
    "\n",
    "faceCascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "img_counter = 0\n",
    "cond=1\n",
    "while cond==1:\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret: \n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "        faces = faceCascade.detectMultiScale(\n",
    "            gray,\n",
    "            scaleFactor=1.1,\n",
    "            minNeighbors=5,\n",
    "            minSize=(30, 30)\n",
    "\n",
    "        )\n",
    "\n",
    "\n",
    "        if (len(faces)>0):\n",
    "\n",
    "\n",
    "                #ser.write(b'done')\n",
    "                #time.sleep(1.25)\n",
    "            print('done')\n",
    "            print(\"Found {0} faces\".format(len(faces)))\n",
    "            img_name = str(img_counter)+\".jpg\"\n",
    "            cv2.imwrite(img_name, frame)\n",
    "            #cv2.imshow(img_name,frame)\n",
    "            with open(img_name, 'r+b') as f:\n",
    "                with Image.open(f) as image:\n",
    "                    cover = resizeimage.resize_cover(image, [558, 313])\n",
    "                    cover.save('test-image-cover.jpg', image.format)\n",
    "            prediction=model.predict([prepare('test-image-cover.jpg')])\n",
    "            if int(prediction[0][0])==0:\n",
    "                play_obj = wave_obj.play()\n",
    "                play_obj.wait_done()\n",
    "            else:\n",
    "                print('ok')\n",
    "            \n",
    "        \n",
    "            \n",
    "            \n",
    "cap.release()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-1a363fa9504d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# channels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m450\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mimg_name\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m\"test.jpg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/imutils/convenience.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(image, width, height, inter)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m# grab the image size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# if both the width and height are None, then return the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from imutils.video import VideoStream\n",
    "import dlib\n",
    "import time\n",
    "from resizeimage import resizeimage\n",
    "import simpleaudio as sa\n",
    "import imutils\n",
    "from threading import Thread\n",
    "\n",
    "def sound_alarm():\n",
    "    filename = 'alarm.wav'\n",
    "    wave_obj = sa.WaveObject.from_wave_file(filename)\n",
    "    play_obj = wave_obj.play()\n",
    "\n",
    "\n",
    "CATEGORIES=[\"yes\",\"no\"]\n",
    "\n",
    "def prepare(filepath):\n",
    "    IMG_SIZE=150\n",
    "    img_array=cv2.imread(filepath,cv2.IMREAD_GRAYSCALE)\n",
    "    new_array=cv2.resize(img_array,(IMG_SIZE,IMG_SIZE))\n",
    "    return new_array.reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "\n",
    "model=tf.keras.models.load_model(\"64x3-CNN.model\")\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "vs = VideoStream(src=0).start()\n",
    "time.sleep(1.0)\n",
    "\n",
    "# loop over frames from the video stream\n",
    "while True:\n",
    "\t# grab the frame from the threaded video file stream, resize\n",
    "\t# it, and convert it to grayscale\n",
    "\t# channels)\n",
    "    frame = vs.read()\n",
    "    frame = imutils.resize(frame, width=450)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    img_name =\"test.jpg\"\n",
    "    cv2.imwrite(img_name, frame)\n",
    "            #cv2.imshow(img_name,frame)\n",
    "    with open(img_name, 'r+b') as f:\n",
    "        with Image.open(f) as image:\n",
    "            cover = resizeimage.resize_cover(image, [558, 313])\n",
    "            cover.save('test-image-cover.jpg', image.format)\n",
    "    prediction=model.predict([prepare('test-image-cover.jpg')])\n",
    "    \n",
    "    \n",
    "    if int(prediction[0][0])==1:\n",
    "        cv2.putText(frame, \"Phone usage\", (10, 30),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "        t = Thread(target=sound_alarm)\n",
    "        t.deamon = True\n",
    "        t.start()\n",
    "\n",
    "           \n",
    "\n",
    "\t# detect faces in the grayscale frame\n",
    "\t\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    " \n",
    "\t# if the `q` key was pressed, break from the loop\n",
    "    if key == ord(\"q\"):\n",
    "        break  \n",
    "\n",
    "# do a bit of cleanup\n",
    "cv2.destroyAllWindows()\n",
    "vs.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
